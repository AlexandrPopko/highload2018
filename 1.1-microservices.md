<p align="right"><img src = "images/tg-logo.png" width="20px" height=20px"> <a href = "https://t.me/docops">docops</a></p>

# Что мы знаем о микросервисах

Вадим Мадисон, Avito

<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->


- [Intro](#intro)
- [Стандартный конвейер разработки микросервиса](#%D1%81%D1%82%D0%B0%D0%BD%D0%B4%D0%B0%D1%80%D1%82%D0%BD%D1%8B%D0%B9-%D0%BA%D0%BE%D0%BD%D0%B2%D0%B5%D0%B9%D0%B5%D1%80-%D1%80%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B8-%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D0%B0)
  - [CLI-push](#cli-push)
  - [Документация](#%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D0%B0%D1%86%D0%B8%D1%8F)
  - [Подготовка пайплайна](#%D0%BF%D0%BE%D0%B4%D0%B3%D0%BE%D1%82%D0%BE%D0%B2%D0%BA%D0%B0-%D0%BF%D0%B0%D0%B9%D0%BF%D0%BB%D0%B0%D0%B9%D0%BD%D0%B0)
  - [Дальше](#%D0%B4%D0%B0%D0%BB%D1%8C%D1%88%D0%B5)
  - [Проверка](#%D0%BF%D1%80%D0%BE%D0%B2%D0%B5%D1%80%D0%BA%D0%B0)
  - [Тесты](#%D1%82%D0%B5%D1%81%D1%82%D1%8B)
  - [Canary tests](#canary-tests)
  - [Squeeze testing](#squeeze-testing)
  - [Прод](#%D0%BF%D1%80%D0%BE%D0%B4)
  - [Что ещё](#%D1%87%D1%82%D0%BE-%D0%B5%D1%89%D1%91)
  - [Дашборд](#%D0%B4%D0%B0%D1%88%D0%B1%D0%BE%D1%80%D0%B4)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->



# Intro

Авито: много сервисов и очень много связей между ними.

Вот основные проблемы от количества:

* Много разных репозиториев. Сложно менять код одновременно везде.
* Много команд пишут код, не пересекаясь с другими. Знания инкапсулируются и плохо передаются между командами. Нет единой картины. Нет человека, который бы всё знал.
* Данные фрагментарны. 

Проблемы с инфраструктурой: слишком много элементов:

* Логирование
* Мониторинг
* Сборка
* Общение
* Трекер задач
* Документация
* Аааааа

Слои: service mesh, k8s, bare metal. Отдельно мониторинг и PaaS. Доклад будет как раз про него.

В платформе есть три основных части:

* Генераторы, управляются через CLI
* Агрегатор (коллектор), управляется через дашборд
* Хранилище (storage) с триггерами на определённые действия.

# Стандартный конвейер разработки микросервиса

## CLI-push

Создаём сервис из шаблона. Вместо первого `git push`.

Долго учили разработчиков правильно начинать работу, но это всё равно становится узким местом при внедрении микросервисов. Поэтому сделали утилиту в помощь разработчикам. Утилита делает вот что:
  
1. Создаёт сервис из шаблона.
1. Разворачивает инфраструктуру для локальной разработки
1. Подключает БД одной командой без конфигов.

Раньше деплой сервиса был сложный и составной.
Сделали проще: один файл `app.toml`.

Базовая валидация:

* Есть докерфайл
* Есть `app.toml`
* Есть документация
* Зависимости в порядке
* УКазаны правила алертов для мониторинга. Владелец сервиса сам это настраивает.

## Документация

Входит:

* Описание сервиса. В двух предложениях, что сервис делает.
* Диаграмма архитектуры.
* Runbook.
* FAQ
* Описание API endpoints
* Labels — к какому продукту, функциональности и структурному подразделению относится сервис.
* Владельцы. Обычно определяем автоматически, но на всякий случай надо.
* Ревью?

## Подготовка пайплайна

* Готовим репозитории
* Делаем пайплайн в Teamcity
* Выставляем права
* Ищем владельцев — вычисляем по push'ам в репозиторий.
    * Одного недостаточно, ненадёжно. Ищем двух.
    * Считаем количество пушей и количество кода в пуше. 
* Регистрируем сервис в Atlas
* Проверяем миграции. Если они потенциально опасны, инфу в Атлас, а сервис в карантин.

## Дальше

* Собираем приложение в докер-образ
* Генерируем хелмчарты для сервиса и его ресурсов
* Создаем админские тикеты на открытие портов
* Юнит-тесты, считаем покрытие кода. Результаты — в Атлас.
* Считаем ограничения по памяти и процессору.

Go + k8s + GOMAXPROCS — придётся оптимизировать производительность. Поможет библиотека [automaxprocs](https://github.com/uber-go/automaxprocs).

## Проверка

Вот что проверяем:

* API endpoints
* Их ответы соответствуют схеме
* Формат логов
* Выставление заголовков при запросах
* Выставление заголовков при отправке сообщений в шину. Тут проверяется связность сервисов.

## Тесты

* Тестируем в закрытом контуре, например hoverfly.io.
* Нагрузочное тестирование — важно.

Нагрузочное тестирование показывает дельту производительности между версиями. Проверяем, что потребление соответствует заданным ограничениям.

* Слишком мало — OOM killer?
* Слишком много — оптимизировать.

## Canary tests

Начинаем с очень малого процента — меньше 0,1%.

Держим от 5 минут до 2 часов.

Смотрим:

* Метрики, специфичные для языка. Например, воркеры php-fpm.
* Ошибки в Sentry
* Статусы ответов
* Время ответов — точное и среднее
* Latency
* Исключения обработанные и необработанные
* Продуктовые метрики, внезапно, тысячи их!

## Squeeze testing

Тестирование через выдавливание. Нагружаем реальными пользователями один инстанс, пока он не нагрузится на 100%, «в полку». Потом добавляем +1, снова смотрим полку, вычисляем дельту. Сравниваем эти данные с данными от искусственной нагрузки.

## Прод

Мониторим на продакшене.

Смотреть только на CPU — неэффективно, потому что соседи фонят. Поэтому смотрим на специфические для приложения метрики. Результаты — в Атлас.

Итого:

* CPU + RAM
* количество запросов в очереди
* время ответа
* ?

## Что ещё

* Миграции, если не осталось версий сервиса ниже Х
* Обновления безопасности
* Если сервис давно не обновлялся — пересобрать для проверки
* Если метрики выходят из нормы — в карантин

## Дашборд

Смотрим на всё сверху в агрегированном виде и делаем выводы.
